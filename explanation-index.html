# Import necessary libraries
# Streamlit for web interface
# Pandas for data manipulation
# Scikit-learn for machine learning algorithms
# LabelEncoder for converting categorical labels to numbers
import streamlit as st
import pandas as pd
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import LabelEncoder

# Function to load and cache the Iris dataset
# Uses @st.cache_data to improve performance by caching the loaded data
@st.cache_data
def load_data():
    """
    Load the Iris dataset from a URL and return as a pandas DataFrame.
    Includes error handling to display an error message if loading fails.
    """
    try:
        url = "https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv"
        return pd.read_csv(url)
    except Exception as e:
        st.error(f"Error loading dataset: {str(e)}")
        return None

df = load_data()

if df is not None:
    # Convert species names (e.g., 'setosa', 'versicolor', 'virginica') to numerical values
    # This is necessary because machine learning algorithms work with numbers
    le = LabelEncoder()
    df["species_encoded"] = le.fit_transform(df["species"])

    # Prepare the features (X) and target variable (y)
    # Features are the measurements: sepal length, sepal width, petal length, petal width
    # Target is the species (converted to numbers)
    X = df[["sepal_length", "sepal_width", "petal_length", "petal_width"]]
    y = df["species_encoded"]

    # Initialize and configure the machine learning models
    # 1. Linear Regression Model
    #    - Simple linear model that predicts continuous values
    #    - Used here for educational purposes to show the difference with Logistic Regression
    linear_model = LinearRegression()
    
    # 2. Logistic Regression Model (configured for multi-class classification)
    #    - Uses L2 regularization to prevent overfitting
    #    - Uses multinomial logistic regression for multi-class classification
    #    - Configured with optimal parameters for the Iris dataset
    logistic_model = LogisticRegression(
        penalty='l2',           # L2 regularization to prevent overfitting
        dual=False,             # Standard formulation of logistic regression
        tol=0.0001,            # Tolerance for stopping criteria
        C=1.0,                 # Regularization strength (lower values specify stronger regularization)
        fit_intercept=True,     # Include intercept term in the model
        intercept_scaling=1,    # Scaling factor for the intercept
        class_weight=None,      # No class weighting since the dataset is balanced
        random_state=42,        # Seed for reproducibility
        solver='lbfgs',         # Optimization algorithm for multinomial logistic regression
        max_iter=1000,         # Maximum number of iterations for convergence
        multi_class='multinomial',  # Multi-class classification using softmax
        verbose=0,             # No verbose output
        warm_start=False,      # Start training from scratch each time
        n_jobs=None,           # Use default number of CPU cores
        l1_ratio=None         # Not needed since we're using L2 penalty
    )
    
    # Train both models on the dataset
    # The models learn from the data to make predictions
    # Linear Regression learns a linear relationship between features and species
    # Logistic Regression learns a probabilistic relationship for multi-class classification
    linear_model.fit(X, y)
    logistic_model.fit(X, y)

    with st.sidebar:
        st.title("ðŸ‘¥ Group Members")
        st.write("""
        - Atornee O. Maala
        - Deejay D. Piaoan
        - Hener P. Lorenzana
        - Shekeina D. Dabalos
        - Joseph B. Rosales
        """)
        st.title("ðŸ”¢ SUPERVISED LEARNING MODEL")
        selected_model = st.radio(
            "Select Algorithm",
            ["Linear Regression", "Logistic Regression"],
            key="model_selection"
        )
        st.image("https://miro.medium.com/v2/resize:fit:720/format:webp/1*H2UmG5L1I5bzFCW006N5Ag.png", caption="Iris Dataset")

    st.title(f"Iris Flower Species Prediction")
    st.markdown("This application uses Machine Learning models to predict the species of an Iris flower based on its dimensions.")

    # Display current model type
    st.markdown(f"### Currently using: {selected_model}")
    st.markdown("Enter the measurements of the Iris flower:")

    col1, col2 = st.columns(2)
    with col1:
        sepal_length = st.number_input("Sepal Length (cm)", min_value=0.0, max_value=10.0, value=5.0, step=0.1)
        sepal_width = st.number_input("Sepal Width (cm)", min_value=0.0, max_value=10.0, value=3.0, step=0.1)
    with col2:
        petal_length = st.number_input("Petal Length (cm)", min_value=0.0, max_value=10.0, value=4.0, step=0.1)
        petal_width = st.number_input("Petal Width (cm)", min_value=0.0, max_value=10.0, value=1.0, step=0.1)

    # Automatically update prediction when inputs change
    if 'species' not in st.session_state or \
            st.session_state.sepal_length != sepal_length or \
            st.session_state.sepal_width != sepal_width or \
            st.session_state.petal_length != petal_length or \
            st.session_state.petal_width != petal_width:

        st.session_state.sepal_length = sepal_length
        st.session_state.sepal_width = sepal_width
        st.session_state.petal_length = petal_length
        st.session_state.petal_width = petal_width

        try:
            input_data = [[sepal_length, sepal_width, petal_length, petal_width]]
            
            if selected_model == "Linear Regression":
                prediction = linear_model.predict(input_data)[0]
                predicted_class = round(prediction)
                species = le.inverse_transform([predicted_class])[0]
                confidence = 1 - abs(prediction - predicted_class)
            else:  # Logistic Regression
                # Get predicted class and probabilities
                prediction = logistic_model.predict(input_data)[0]
                proba = logistic_model.predict_proba(input_data)[0]
                species = le.inverse_transform([prediction])[0]
                
                # Calculate confidence as the probability of the predicted class
                confidence = proba[prediction]
                
                # Add class probabilities to session state
                st.session_state.class_probabilities = {
                    le.inverse_transform([i])[0]: proba[i] * 100
                    for i in range(len(proba))
                }
                
                # Add detailed prediction information to session state
                st.session_state.logistic_details = {
                    'coefficients': logistic_model.coef_.tolist(),
                    'intercept': logistic_model.intercept_.tolist(),
                    'n_iter': logistic_model.n_iter_,
                    'classes': le.inverse_transform(logistic_model.classes_).tolist()
                }

            st.session_state.species = species
            st.session_state.confidence = confidence
        except:
            st.session_state.species = None
            st.session_state.confidence = None

    # Display prediction result with confidence level
    if 'species' in st.session_state and st.session_state.species:
        confidence_percent = st.session_state.confidence * 100
        
        # Color coding for confidence levels:
        # Green: High confidence (80% or above)
        # Orange: Medium confidence (50-80%)
        # Red: Low confidence (below 50%)
        if confidence_percent >= 80:
            color = "green"
        elif confidence_percent < 50:
            color = "red"
        else:
            color = "orange"

        # Display the prediction with confidence level
        st.markdown(
            f"### Predicted Species: **{st.session_state.species.capitalize()}** <span style='color:{color}'>**({confidence_percent:.2f}%)**</span>",
            unsafe_allow_html=True)
        
        # If using Logistic Regression, show additional details
        if selected_model == "Logistic Regression" and 'logistic_details' in st.session_state:
            st.subheader("Logistic Regression Details")
            st.write(f"Number of iterations: {st.session_state.logistic_details['n_iter']}")
            st.write(f"Classes: {st.session_state.logistic_details['classes']}")
            
            # Show probability distribution for each class
            st.subheader("Class Probabilities")
            for species, prob in st.session_state.class_probabilities.items():
                st.write(f"- {species}: {prob:.2f}%")
else:
    st.warning("Dataset failed to load. Please check the data source.")
